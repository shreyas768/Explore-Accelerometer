---
title: "PML project"
author: "Shreyas Shukla"
date: "July 9, 2016"
output: md_document
---
Introduction
=============

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. 


Loading required Library and datasets
======================================
**x** represents train data while **y** represents test data.
```{r}
suppressMessages(library(caret))
suppressMessages(library(rpart))
suppressMessages(library(randomForest))
suppressMessages(library(rattle))
x <- read.csv("C:/Users/shreyas768/Downloads/pml-training.csv", sep=",", na.strings=c("","NA","#DIV/0!"), stringsAsFactor=FALSE, header = TRUE)
y <- read.csv("C:/Users/shreyas768/Downloads/pml-testing.csv", sep=",", na.strings=c("","NA","#DIV/0!), stringsAsFactors = FALSE", header =TRUE))
dim(x)
dim(y)
```


Removing Unnecessary columns(Data cleaning)
===========================================
The training dataset has 19622 observations and 160 variables and testing dataset has 20 observations and equal number of variables. The loaded data contains some columns which has only NA values and hence they need to be removed.

```{r}
x <- x[,colSums(!is.na(x)) > 0]
x <- x[, colSums(is.na(x)) == 0]
y <- y[,colSums(!is.na(y)) > 0]
```

Also,first seven predictors have very low predicting power for outcome classe. Hence, we will remove them
```{r}
x <- x[,-c(1:7)]
y <- y[,-c(1:7)]
dim(x)
dim(y)
```
The training dataset now has 19622 observations and 53 variables and testing dataset has 20 observations and equal number of variables.

Data Spliting
===============
We split the cleaned Training dataset **x** further into Training set (**Train**, 70%) for prediction and a validation set (**Test**,30%)  
```{r}
set.seed(1234)
x$classe <- as.factor(x$classe)
inTrain <- createDataPartition(x$classe,p=0.7,list = FALSE)
Train <- x[inTrain,]
Test <- x[-inTrain,]
```

Prediction Algorithm
====================

Let us first use Classification trees to predict the outcome.

Classification Trees
====================

```{r}
TC <- trainControl(method = "cv", number = 5)
modFit <- train(classe ~ .,method="rpart",data=Train, trControl=TC)
plot(modFit)
```
```{r}
fancyRpartPlot(modFit$finalModel)
```

Predict outcomes using validation (**test**) set
```{r}
r <- predict(modFit,Test)
(t <- confusionMatrix(Test$classe,r))
 t$overall[1]
```

Accuracy rate is only 48.9%, i.e out-of-sample is 51.1% and hence classification tree doesn't predict the outcome well. We will now try Random Forrest.

Random Forests
==============


```{r}
control <- trainControl(method = "cv", number = 5,allowParallel = TRUE)
(fit <- randomForest(classe~.,data = Train, importance = TRUE))
pred <- predict(fit,Test,type = "class")
s <- confusionMatrix(Test$classe,pred)
s$overall[1]
```

The accuracy is `r s$overall[1]` and so the out-of-sample error rate is `r 1-s$overall[1]`. Thus, for this dataset Random Forests is way better than Classification Tree. Now we will use Random Forests to predict the outcome variable Classe of Testing dataset (**y**).

Prediction
==========
```{r}
predict(fit,y)
```


